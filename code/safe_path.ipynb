{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af30607c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Il progetto **SAFE PATH** nasce con l’obiettivo di **predire il rischio di criminalità** lungo le strade urbane e guidare gli utenti , in particolare donne e bambini, attraverso **percorsi pedonali più sicuri**, grazie all’uso di tecniche avanzate di **intelligenza artificiale su grafi**.\n",
    "\n",
    "In particolare, il sistema si propone di:\n",
    "- Analizzare i dati storici dei crimini nella città di **Chicago**.\n",
    "- Costruire un **grafo stradale pedonale** realistico basato su OpenStreetMap.\n",
    "- Stimare il **rischio associato a ciascun segmento stradale** con un modello predittivo.\n",
    "- Calcolare il **percorso ottimale in base alla sicurezza**, non solo alla distanza.\n",
    "\n",
    "Il progetto unisce **machine learning**, **analisi spaziale** e **network science** per migliorare la vivibilità e la sicurezza urbana.\n",
    "\n",
    "\n",
    "Le **Graph Neural Networks** (GNN) sono un tipo di rete neurale progettata per operare su **strutture a grafo**, dove i dati non sono indipendenti ma collegati da relazioni (nodi e archi).\n",
    "\n",
    "Nel mio contesto:\n",
    "- **I nodi** rappresentano i punti del grafo stradale (intersezioni).\n",
    "- **Gli archi** rappresentano i segmenti stradali (strade percorribili).\n",
    "- Ogni arco ha associate feature come: **ora media dei crimini, rischio di zona, lunghezza, e rischio stimato**.\n",
    "\n",
    "Le GNN sono in grado di:\n",
    "- Tenere conto del **contesto locale e delle connessioni** tra strade vicine.\n",
    "- **Predire il rischio** su ogni arco anche in zone meno documentate.\n",
    "- Generalizzare sfruttando la **struttura connettiva** del grafo urbano.\n",
    "\n",
    "Le GNN rappresentano lo stato dell’arte nell’analisi su grafi e trovano applicazione in campi come:\n",
    "- Mobilità urbana\n",
    "- Sicurezza informatica\n",
    "- Scienze biologiche\n",
    "- Recommender systems\n",
    "\n",
    "\n",
    "Un’applicazione concreta di **AI per il bene pubblico**, estendibile a qualsiasi città dotata di dati geospaziali e open data sui reati.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21cb60b",
   "metadata": {},
   "source": [
    "## 1. **Pulizia e Preparazione dei Dati per il progetto SAFE PATH**\n",
    "\n",
    "Questo blocco di codice esegue la pulizia e la preparazione del dataset dei crimini di Chicago per l’analisi e la modellazione del rischio.\n",
    "\n",
    "**Step principali:**\n",
    "\n",
    "- **Import delle librerie**  \n",
    "  Importa pandas, numpy e strumenti di clustering e normalizzazione da scikit-learn.\n",
    "\n",
    "- **Caricamento del dataset**  \n",
    "  Carica il file CSV dei crimini in un DataFrame pandas.\n",
    "\n",
    "- **Selezione delle colonne utili**  \n",
    "  Tiene solo le colonne rilevanti: data, tipo di crimine, luogo, arresto, domesticità, coordinate, area e blocco.\n",
    "\n",
    "- **Rimozione dei dati mancanti**  \n",
    "  Elimina le righe senza coordinate o tipo di crimine.\n",
    "\n",
    "- **Parsing della data e ora**  \n",
    "  Converte la colonna 'Date' in formato datetime, estrae anno e ora.\n",
    "\n",
    "- **Filtro temporale**  \n",
    "  Tiene solo i crimini dal 2018 in poi.\n",
    "\n",
    "- **Filtro geografico**  \n",
    "  Tiene solo i crimini avvenuti entro i limiti geografici di Chicago (per evitare outlier).\n",
    "\n",
    "- **Calcolo del peso orario**  \n",
    "  Applica una funzione che assegna un peso di rischio maggiore ai crimini avvenuti di notte.\n",
    "\n",
    "- **Pulizia del campo Block**  \n",
    "  Anonimizza il campo 'Block' sostituendo i numeri civici con la stringa 'BLOCK'.\n",
    "\n",
    "- **Assegnazione dei pesi ai tipi di crimine**  \n",
    "  Ogni tipo di crimine riceve un peso di gravità (es. HOMICIDE=1.0, THEFT=0.3, ecc.).\n",
    "\n",
    "- **Calcolo del rischio pesato**  \n",
    "  Calcola il rischio effettivo di ogni evento come prodotto tra peso orario e peso del crimine.\n",
    "\n",
    "- **Normalizzazione dei booleani**  \n",
    "  Converte le colonne 'Arrest' e 'Domestic' in valori 0/1.\n",
    "\n",
    "- **Clustering geografico**  \n",
    "  Applica KMeans per suddividere la città in 40 zone (GeoZone) sulla base delle coordinate.\n",
    "\n",
    "- **Calcolo del rischio medio per zona**  \n",
    "  Calcola il rischio medio normalizzato e il conteggio dei crimini per ogni zona.\n",
    "\n",
    "- **Salvataggio dei dati puliti**  \n",
    "  Salva il DataFrame pulito e i centroidi dei cluster per usi successivi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd10d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pulizia, clustering e salvataggi completati.\n"
     ]
    }
   ],
   "source": [
    "# SAFE PATH - Fase 1: Pulizia e preparazione dati (v3 con clustering geografico)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# --------------------------\n",
    "# 0. Caricamento dataset\n",
    "# --------------------------\n",
    "file_path = \"../data/Crimes_-_2001_to_Present_20250621.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --------------------------\n",
    "# 1. Selezione colonne utili\n",
    "# --------------------------\n",
    "columns_to_keep = [\n",
    "    'Date', 'Primary Type', 'Location Description', 'Arrest', 'Domestic',\n",
    "    'Latitude', 'Longitude', 'Community Area', 'Block'\n",
    "]\n",
    "df = df[columns_to_keep].dropna(subset=['Latitude', 'Longitude', 'Primary Type'])\n",
    "\n",
    "# --------------------------\n",
    "# 2. Parsing data/ora ➜ estrai Year e Hour\n",
    "# --------------------------\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
    "df = df.dropna(subset=['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Hour'] = df['Date'].dt.hour\n",
    "\n",
    "# --------------------------\n",
    "# 3. Filtro temporale (dal 2018 in poi)\n",
    "# --------------------------\n",
    "df = df[df['Year'] >= 2018]\n",
    "\n",
    "# --------------------------\n",
    "# 4. Filtro geografico (evita outlier)\n",
    "# --------------------------\n",
    "df = df[ (df['Latitude'].between(41.64, 42.05)) & (df['Longitude'].between(-87.95, -87.5))]\n",
    "\n",
    "# --------------------------\n",
    "# 5. Calcolo peso orario (TimeWeight)\n",
    "# --------------------------\n",
    "def time_weight(hour: int) -> float:\n",
    "    if 0 <= hour < 4:\n",
    "        return 1.5\n",
    "    elif 4 <= hour < 6:\n",
    "        return 0.9\n",
    "    elif 6 <= hour < 18:\n",
    "        return 0.45\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "df['TimeWeight'] = df['Hour'].apply(time_weight)\n",
    "\n",
    "# --------------------------\n",
    "# 6. Pulizia campo Block\n",
    "# --------------------------\n",
    "df['Block'] = df['Block'].str.replace(r'\\d{3}X', 'BLOCK', regex=True)\n",
    "\n",
    "# --------------------------\n",
    "# 7. Pesi di gravità per tipo di crimine\n",
    "# --------------------------\n",
    "default_weight = 0.2\n",
    "crime_weights = {cat: default_weight for cat in df['Primary Type'].unique()}\n",
    "crime_weights.update({\n",
    "    'HOMICIDE': 1.0,\n",
    "    'CRIMINAL SEXUAL ASSAULT': 0.95,\n",
    "    'KIDNAPPING': 0.82,\n",
    "    'ROBBERY': 0.80,\n",
    "    'ASSAULT': 0.77,\n",
    "    'BATTERY': 0.63,\n",
    "    'ARSON': 0.52,\n",
    "    'BURGLARY': 0.53,\n",
    "    'MOTOR VEHICLE THEFT': 0.45,\n",
    "    'CRIMINAL DAMAGE': 0.34,\n",
    "    'THEFT': 0.30,\n",
    "    'NARCOTICS': 0.25,\n",
    "})\n",
    "\n",
    "df['CrimeWeight'] = df['Primary Type'].map(crime_weights)\n",
    "df['WeightedCrime'] = df['TimeWeight'] * df['CrimeWeight']  #calcolato per ogni signolo evento\n",
    "\n",
    "# --------------------------\n",
    "# 8. Normalizzazione booleani\n",
    "# --------------------------\n",
    "df['Arrest'] = df['Arrest'].astype(int)\n",
    "df['Domestic'] = df['Domestic'].astype(int)\n",
    "\n",
    "# --------------------------\n",
    "# 9. Categoria testuale e coordinate\n",
    "# --------------------------\n",
    "df['Crime Category'] = df['Primary Type']\n",
    "df['geometry'] = list(zip(df.Longitude, df.Latitude))\n",
    "\n",
    "# --------------------------\n",
    "# 10. Clustering geografico per zone\n",
    "# --------------------------\n",
    "coords = df[['Latitude', 'Longitude']]\n",
    "n_clusters = 40\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(coords)\n",
    "df['GeoZone'] = kmeans.labels_\n",
    "\n",
    "# --------------------------\n",
    "# 11. ZoneRisk + conteggio eventi per zona\n",
    "# --------------------------\n",
    "zone_risk = df.groupby('GeoZone')['WeightedCrime'].mean().reset_index()\n",
    "scaler = MinMaxScaler()\n",
    "zone_risk['NormalizedZoneRisk'] = scaler.fit_transform(zone_risk[['WeightedCrime']])\n",
    "df = df.merge(zone_risk[['GeoZone', 'NormalizedZoneRisk']], on='GeoZone', how='left')\n",
    "\n",
    "zone_counts = df.groupby('GeoZone').size().reset_index(name='CrimeCount')\n",
    "df = df.merge(zone_counts, on='GeoZone', how='left')\n",
    "\n",
    "df['CrimeCountLog'] = np.log1p(df['CrimeCount'])  # log(1 + x) -> Logarithmic Transformation log1p per ev itare problemi se x vale 0 e mantiene le roporzioni per valori piccoli e permette sia di stabilizzare la varianza che rendere i dati piu gaussiani\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 12. Salvataggio dataset pulito\n",
    "# --------------------------\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "df.reset_index(drop=True).to_csv(\"../data/cleaned_clustered_crime_data.csv\", index=False)\n",
    "\n",
    "# --------------------------\n",
    "# 13. Salvataggio centroidi cluster per mappa\n",
    "# --------------------------\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=[\"Latitude\", \"Longitude\"])\n",
    "centroids.to_json(\"../data/cluster_centroids.json\", orient=\"records\")\n",
    "\n",
    "print(\"✅ Pulizia, clustering e salvataggi completati.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e591240",
   "metadata": {},
   "source": [
    "### ATTRIBUTI CHE ABBIAMO ORA\n",
    "\n",
    "| Attributo              | Descrizione                                                                                   |\n",
    "|------------------------|----------------------------------------------------------------------------------------------|\n",
    "| Date                   | Data e ora del crimine                                                                       |\n",
    "| Primary Type           | Categoria principale del reato (es. THEFT, ASSAULT)                                          |\n",
    "| Location Description   | Dove è avvenuto (es. STREET, APARTMENT)                                                      |\n",
    "| Arrest                 | 1 = arresto effettuato, 0 = no                                                               |\n",
    "| Domestic               | 1 = reato domestico                                                                          |\n",
    "| Latitude, Longitude    | Coordinate geografiche del reato                                                             |\n",
    "| Community Area         | Area urbana di Chicago (intorno a 77 aree totali)                                            |\n",
    "| Block                  | Strada del crimine, anonimizzata                                                             |\n",
    "| Year, Hour             | Anno e ora del giorno                                                                        |\n",
    "| TimeWeight             | Peso orario del rischio (es. notte = più alto)                                               |\n",
    "| CrimeWeight            | Peso di gravità del crimine                                                                  |\n",
    "| WeightedCrime          | Rischio effettivo TOTALE: rischio pesato rispetto al crimine e alla fascia temporale         |\n",
    "| Crime Category         | Alias per Primary Type                                                                       |\n",
    "| geometry               | Tupla (lon, lat) utile per geoposizionamento                                                 |\n",
    "| GeoZone                | ID del cluster geografico                                                                    |\n",
    "| NormalizedZoneRisk     | Rischio medio normalizzato per zona (0–1)                                                    |\n",
    "| CrimeCount             | Numero totale di crimini in quella zona                                                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569b2ed",
   "metadata": {},
   "source": [
    "### 2. **Preparazione delle feature spaziali e rischio sugli archi del grafo**\n",
    "\n",
    "Questo blocco di codice esegue i seguenti passaggi fondamentali:\n",
    "\n",
    "1. **Caricamento dei dati dei crimini**  \n",
    "   - Si carica il file CSV dei crimini già pulito e clusterizzato.\n",
    "   - Si estraggono le coordinate (latitudine, longitudine) e il rischio pesato (`WeightedCrime`) per ogni evento.\n",
    "\n",
    "2. **Costruzione di un KDTree**  \n",
    "   - Si crea una struttura KDTree sulle coordinate dei crimini per poter trovare rapidamente i crimini più vicini a un punto qualsiasi della città.\n",
    "\n",
    "3. **Funzioni di utilità**  \n",
    "   - `get_crimes_near(lat, lon, k=5)`: restituisce i k crimini più vicini a una posizione data.\n",
    "   - `get_local_features(lat, lon)`: calcola statistiche locali (ora media, zona più frequente, rischio medio normalizzato, numero di crimini) attorno a una posizione.\n",
    "\n",
    "4. **Costruzione del grafo stradale**  \n",
    "   - Si scarica la rete stradale pedonale di Chicago tramite OSMnx.\n",
    "   - Il grafo viene proiettato in coordinate metriche (UTM) per calcolare distanze reali.\n",
    "\n",
    "5. **Calcolo della lunghezza degli archi**  \n",
    "   - Per ogni arco (strada) del grafo, si calcola la lunghezza in metri usando la geometria reale se disponibile, altrimenti la distanza euclidea tra i nodi.\n",
    "\n",
    "6. **Estrazione delle feature per ogni arco**  \n",
    "   - Per ogni arco si calcolano:\n",
    "     - Latitudine e longitudine del centro dell’arco.\n",
    "     - Statistiche locali sui crimini vicini (ora media, zona, rischio zona, conteggio crimini).\n",
    "     - La lunghezza dell’arco.\n",
    "     - Il rischio vero (`risk_true`): media pesata del rischio dei crimini vicini, pesata in base alla distanza (più un crimine è vicino, più pesa).\n",
    "\n",
    "7. **Risultato**  \n",
    "   - Ogni arco del grafo ora contiene tutte le feature necessarie per l’analisi e la predizione del rischio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ff67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import KDTree\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "import pickle\n",
    "from geopy.distance import great_circle\n",
    "\n",
    "\n",
    "# === Prepara KDTree crimini per analisi spaziale ===\n",
    "crime_df = pd.read_csv(\"../data/cleaned_clustered_crime_data.csv\")\n",
    "crime_coords = crime_df[['Latitude', 'Longitude']].to_numpy()\n",
    "crime_weights = crime_df['WeightedCrime'].to_numpy()\n",
    "crime_tree = KDTree(np.radians(crime_coords))\n",
    "\n",
    "def get_crimes_near(lat, lon, k=5):\n",
    "    coord_rad = np.radians([[lat, lon]])\n",
    "    dists, idxs = crime_tree.query(coord_rad, k=k)\n",
    "    return crime_df.iloc[idxs[0]]\n",
    "\n",
    "def get_local_features(lat, lon):\n",
    "    crimes_near = get_crimes_near(lat, lon, k=5)\n",
    "    if crimes_near.empty:\n",
    "        return 0.0, 0, 0.0, 0\n",
    "    hour_avg = crimes_near['Hour'].mean()\n",
    "    zone_ids = crimes_near['GeoZone'].values\n",
    "    zone = np.bincount(zone_ids).argmax()  # zona più frequente\n",
    "    zone_info = crimes_near[crimes_near['GeoZone'] == zone].iloc[0]\n",
    "    return hour_avg, zone, zone_info['NormalizedZoneRisk'], zone_info['CrimeCount']\n",
    "\n",
    "# === Carica grafo e prepara GeoDataFrame ===\n",
    "G = ox.graph_from_place(\"Chicago, Illinois, USA\", network_type='walk')\n",
    "G = ox.project_graph(G) #standard coordinate in UTM (Universal Transverse Mercator) per calcolare le distanze in metri\n",
    "\n",
    "# Aggiunge manualmente la lunghezza ad ogni arco (in metri)\n",
    "for u, v, k, data in G.edges(keys=True, data=True):\n",
    "    if 'geometry' in data: #se c e una geometria, uso quella per calcolare la lunghezza\n",
    "        length = data['geometry'].length  # in metri, se il grafo è proiettato (UTM)\n",
    "    else: #altrimenti uso la distanza euclidea\n",
    "        x1, y1 = G.nodes[u]['x'], G.nodes[u]['y']\n",
    "        x2, y2 = G.nodes[v]['x'], G.nodes[v]['y']\n",
    "        length= ox.distance.euclidean(x1, y1, x2, y2)  # in metri\n",
    "        \n",
    "    G[u][v][k]['length'] = length\n",
    "\n",
    "edges_gdf = ox.graph_to_gdfs(G, nodes=False, edges=True)\n",
    "edges_gdf = edges_gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Calcola feature personalizzate\n",
    "\n",
    "feature_matrix = []\n",
    "for (u, v, k), row in edges_gdf.iterrows():\n",
    "    geom = row['geometry']\n",
    "\n",
    "    centroide = geom.centroid\n",
    "    lat, lon = centroide.y, centroide.x\n",
    "    hour, geozone, zonerisk, crimecount = get_local_features(lat, lon)\n",
    "\n",
    "    G[u][v][k]['lat'] = lat\n",
    "    G[u][v][k]['lon'] = lon\n",
    "    G[u][v][k]['hour'] = hour\n",
    "    G[u][v][k]['GeoZone'] = geozone\n",
    "    G[u][v][k]['NormalizedZoneRisk'] = zonerisk\n",
    "    G[u][v][k]['CrimeCount'] = crimecount\n",
    "    G[u][v][k]['length'] = G[u][v][k].get('length')\n",
    "\n",
    "    crimes_near = get_crimes_near(lat, lon, k=5)\n",
    "\n",
    "    if not crimes_near.empty:\n",
    "        # Calcola distanza geodetica in metri tra centro arco e crimini vicini\n",
    "        dists = crimes_near.apply(\n",
    "            lambda row: great_circle((lat, lon), (row['Latitude'], row['Longitude'])).meters,\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Aggiungi un piccolo epsilon per evitare divisione per zero\n",
    "        weights = 1 / (dists + 1e-3)\n",
    "\n",
    "        # Calcolo della media pesata del rischio, un crimine avvenuto a 30 metri è piu importante di uno avvenuto a 400 per esempio\n",
    "        weighted_avg = np.average(crimes_near['WeightedCrime'], weights=weights)\n",
    "\n",
    "        G[u][v][k]['risk_true'] = float(weighted_avg)\n",
    "    else:\n",
    "        G[u][v][k]['risk_true'] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d121238",
   "metadata": {},
   "source": [
    "### Salvataggio del grafo e delle feature spaziali\n",
    "\n",
    "Questo blocco di codice si occupa di salvare i dati elaborati per futuri riutilizzi e per eventuali analisi o visualizzazioni GIS:\n",
    "\n",
    "1. **Crea la cartella di destinazione**  \n",
    "   - Se la cartella `../data` non esiste, viene creata automaticamente.\n",
    "\n",
    "2. **Salva il grafo completo**  \n",
    "   - Il grafo `G`, arricchito con tutte le feature di rischio e statistiche locali sugli archi, viene salvato in formato pickle (`graph_with_features.pkl`).  \n",
    "   - Questo permette di ricaricare rapidamente il grafo senza dover ripetere tutta la fase di calcolo delle feature.\n",
    "\n",
    "3. **Salva il GeoDataFrame degli archi**  \n",
    "   - Il GeoDataFrame `edges_gdf`, che contiene tutte le informazioni sugli archi (inclusa la geometria e le feature di rischio), viene salvato in formato GeoJSON (`edges_with_features.geojson`).  \n",
    "   - Questo formato è compatibile con software GIS come QGIS e può essere usato per visualizzazioni o analisi spaziali avanzate.\n",
    "\n",
    "4. **Messaggio di conferma**  \n",
    "   - Alla fine viene stampato un messaggio per confermare che il salvataggio è avvenuto con successo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3db12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafo e GeoDataFrame salvati.\n"
     ]
    }
   ],
   "source": [
    "#Salvo il grafo per futuri riutilizzi\n",
    "# Crea cartella se non esiste\n",
    "import os \n",
    " \n",
    "# Salva grafo completo\n",
    "with open(\"../data/graph_with_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(G, f)\n",
    "\n",
    "# Salva come GeoDataFrame (per GIS o debug)\n",
    "edges_gdf.to_file(\"../data/edges_with_features.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(\"Grafo e GeoDataFrame salvati.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbad2d7",
   "metadata": {},
   "source": [
    "### 3. **Verifica della completezza degli attributi sugli archi del grafo**\n",
    "\n",
    "Questo blocco di codice serve a **controllare che ogni arco del grafo** abbia tutti gli attributi necessari per le fasi successive di analisi e modellazione.  \n",
    "Gli attributi richiesti sono:  \n",
    "- `length`  \n",
    "- `lat`  \n",
    "- `lon`  \n",
    "- `hour`  \n",
    "- `GeoZone`  \n",
    "- `NormalizedZoneRisk`  \n",
    "- `CrimeCount`  \n",
    "- `risk_true`  \n",
    "\n",
    "**Cosa fa il codice:**\n",
    "1. **Definisce la lista di attributi obbligatori** per ogni arco.\n",
    "2. **Scorre tutti gli archi** del grafo `G` e verifica se manca qualcuno di questi attributi.\n",
    "3. **Stampa un messaggio di warning** per ogni arco che ha attributi mancanti, indicando quali sono.\n",
    "4. Alla fine, **stampa il numero totale di archi** nel grafo e nel GeoDataFrame, utile per confrontare che non ci siano discrepanze tra le due strutture dati.\n",
    "\n",
    "**Motivazione delle scelte:**\n",
    "- Questo controllo è fondamentale perché, nelle fasi successive (ad esempio la conversione per PyTorch Geometric o il salvataggio per GIS), **tutti gli archi devono avere lo stesso set di feature** e dello stesso tipo.  \n",
    "- Se anche solo un arco manca di un attributo, si rischiano errori difficili da debuggare o risultati incoerenti nei modelli di machine learning.\n",
    "- Il confronto tra il numero di archi nel grafo e nel GeoDataFrame permette di individuare eventuali problemi di sincronizzazione o perdita di dati tra le due rappresentazioni.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02b8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot edges in G: 975168\n",
      "Tot edges in edges_gdf: 975168\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "required_attrs = {\n",
    "    \"length\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"hour\",\n",
    "    \"GeoZone\",\n",
    "    \"NormalizedZoneRisk\",\n",
    "    \"CrimeCount\",\n",
    "    \"risk_true\"\n",
    "}\n",
    "\n",
    "for u, v, k, data in G.edges(keys=True, data=True):\n",
    "    missing = [attr for attr in required_attrs if attr not in data]\n",
    "    if missing:\n",
    "        print(f\"Edge ({u}, {v}, {k}) missing attributes: {missing}\")\n",
    "\n",
    "\n",
    "print(f\"Tot edges in G: {len(G.edges(keys=True))}\")\n",
    "print(f\"Tot edges in edges_gdf: {len(edges_gdf)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56633b7",
   "metadata": {},
   "source": [
    "### 4. **Pulizia degli attributi dei nodi prima della conversione a PyTorch Geometric**\n",
    "\n",
    "Questo blocco di codice serve a **rimuovere tutti gli attributi dai nodi del grafo** prima di convertirlo in un oggetto PyTorch Geometric\n",
    "\n",
    "\n",
    "- In questo progetto **le predizioni vengono fatte sugli archi** (edge-level), non sui nodi.\n",
    "- PyTorch Geometric, durante la conversione con `from_networkx()`, può generare errori o conflitti se i nodi hanno attributi eterogenei o inutili, soprattutto se non sono coerenti tra loro o non servono al modello.\n",
    "- Pulendo tutti gli attributi dei nodi si evita che informazioni non necessarie o formati incompatibili causino problemi nella pipeline di machine learning.\n",
    "- In questo modo si garantisce che **solo le feature degli archi** (che sono quelle rilevanti per la predizione del rischio) vengano mantenute e utilizzate dal modello.\n",
    "\n",
    "Era dunque necessario attuare una una misura di sicurezza per evitare errori di conversione e garantire che il grafo sia pronto per l’uso in PyTorch Geometric, mantenendo solo le informazioni realmente utili per il task di predizione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c75c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💡 Esegui prima della conversione con from_networkx() \n",
    "#rimuovo gli attributi dai nodi (perché io uso gli archi per fare predizione)  per evitare conflitti nel blocco successivo, da rivedere se uniformare gli attributi o eliminarli e basta cosi\n",
    "for _, data in G.nodes(data=True):\n",
    "    data.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7d296",
   "metadata": {},
   "source": [
    "\n",
    "### 5. **Controllo dell’omogeneità dei tipi degli attributi sugli archi**\n",
    "\n",
    "Questo blocco di codice serve a **verificare che ogni attributo degli archi del grafo abbia sempre lo stesso tipo** (ad esempio, tutti float o tutti int) per garantire la compatibilità e la robustezza della pipeline, evitando errori dovuti a tipi misti nei dati.\n",
    "\n",
    "- PyTorch Geometric richiede che ogni feature abbia **lo stesso tipo su tutti gli archi** (ad esempio, tutti float32 o tutti int).\n",
    "- Se anche solo un arco ha un tipo diverso (ad esempio `np.float64` invece di `float`), la conversione con `from_networkx()` può fallire o generare errori difficili da interpretare.\n",
    "- Questo controllo permette di **individuare subito eventuali inconsistenze** nei tipi degli attributi, così da poterli uniformare prima della conversione.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e46513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length → tipi trovati: {<class 'float'>, <class 'numpy.float64'>}\n",
      "lat → tipi trovati: {<class 'float'>}\n",
      "lon → tipi trovati: {<class 'float'>}\n",
      "hour → tipi trovati: {<class 'numpy.float64'>}\n",
      "GeoZone → tipi trovati: {<class 'numpy.int64'>}\n",
      "NormalizedZoneRisk → tipi trovati: {<class 'numpy.float64'>}\n",
      "CrimeCount → tipi trovati: {<class 'numpy.int64'>}\n",
      "risk_true → tipi trovati: {<class 'float'>}\n"
     ]
    }
   ],
   "source": [
    "for attr in [\"length\", \"lat\", \"lon\", \"hour\", \"GeoZone\", \"NormalizedZoneRisk\", \"CrimeCount\", \"risk_true\"]:\n",
    "    types = set(type(G[u][v][k].get(attr)) for u, v, k in G.edges(keys=True))\n",
    "    print(f\"{attr} → tipi trovati: {types}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807164dc",
   "metadata": {},
   "source": [
    "Torch Geometric è molto rigido: vuole tutti gli attributi dello stesso tipo per ogni feature. In particolare, non tollera differenze tra float e np.float64. Quindi funzione: uniformate_attributes\n",
    "\n",
    "PyTorch (e torch_geometric) lavora su torch.float32 o float, e non tollera bene oggetti NumPy puri (np.float64, np.int64, ecc.) nei dizionari, soprattutto in from_networkx.\n",
    "\n",
    "Usare float ti garantisce massima compatibilità e meno errori criptici.\n",
    "\n",
    "La differenza pratica tra float e np.float64 è irrilevante in precisione nella maggior parte dei casi (sono entrambi a 64 bit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64506f",
   "metadata": {},
   "source": [
    "Questo blocco di codice serve a **verificare che ogni arco del grafo abbia tutti gli attributi richiesti** (non solo che siano dello stesso tipo, ma che siano proprio presenti).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04427837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Archi con attributi mancanti: 0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "required_attrs = {\n",
    "    \"length\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"hour\",\n",
    "    \"GeoZone\",\n",
    "    \"NormalizedZoneRisk\",\n",
    "    \"CrimeCount\",\n",
    "    \"risk_true\"\n",
    "}\n",
    "\n",
    "missing_edges = []\n",
    "for u, v, k, data in G.edges(keys=True, data=True):\n",
    "    missing = required_attrs - data.keys()\n",
    "    if missing:\n",
    "        missing_edges.append(((u, v, k), missing))\n",
    "\n",
    "print(f\"🔎 Archi con attributi mancanti: {len(missing_edges)}\")\n",
    "if missing_edges:\n",
    "    for i, (edge, missing) in enumerate(missing_edges[:5]):\n",
    "        print(f\"  Arco {edge} manca: {missing}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c2de0a",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------\n",
    "**Qual è la differenza tra il blocco 3 e il blocco 5?**\n",
    "\n",
    "- **Questo blocco controlla la *presenza* degli attributi**: per ogni arco verifica che ci siano *tutti* gli attributi richiesti (non importa il tipo, ma che esistano).\n",
    "- **Il blocco precedente controllava l'*omogeneità dei tipi***: per ogni attributo, verificava che il tipo fosse sempre lo stesso su tutti gli archi (ad esempio, tutti float o tutti int).\n",
    "- **Perché servono entrambi?**  \n",
    "  - Se manca anche solo un attributo su un arco, la conversione verso PyTorch Geometric (`from_networkx`) può fallire o produrre dati inconsistenti.\n",
    "  - Se gli attributi ci sono ma hanno tipi diversi, si possono avere errori di tipo o comportamenti imprevisti nei modelli ML.\n",
    "\n",
    "\n",
    " \n",
    "  - Blocco 5: garantisce che la struttura dei dati sia completa e omogenea (tutti gli archi hanno tutte le feature richieste).\n",
    "  - Blocco 3: garantisce che i dati siano anche coerenti come tipo (tutti float, tutti int, ecc.).\n",
    "\n",
    "Entrambi sono fondamentali per una pipeline robusta e senza errori nella fase di conversione\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa40aec3",
   "metadata": {},
   "source": [
    "## 6. **Uniformare i tipi degli attributi sugli archi**\n",
    "\n",
    "Questo blocco definisce la funzione `uniformate_attributes(G)`, che **uniforma i tipi degli attributi sugli archi del grafo**.  \n",
    "Serve a garantire che ogni attributo abbia sempre lo stesso tipo su tutti gli archi, requisito fondamentale per la compatibilità con PyTorch Geometric.\n",
    "\n",
    "**Cosa fa la funzione:**\n",
    "- Per ogni arco del grafo `G`, prende solo gli attributi richiesti:  \n",
    "  `'length', 'lat', 'lon', 'hour', 'GeoZone', 'NormalizedZoneRisk', 'CrimeCount', 'risk_true'`\n",
    "- Per ogni attributo:\n",
    "  - Se è `GeoZone` o `CrimeCount`, lo converte in `int` (usando la funzione `safe_int`).\n",
    "  - Tutti gli altri attributi vengono convertiti in `float` (usando la funzione `safe_float`).\n",
    "  - Se la conversione fallisce, assegna `nan` (per i float) o `-1` (per gli int).\n",
    "- Sostituisce il dizionario degli attributi dell’arco con quello appena creato, così **tutti gli archi avranno solo questi attributi e tutti dello stesso tipo**.\n",
    "\n",
    "**Perché è importante:**\n",
    "- PyTorch Geometric richiede che ogni feature abbia lo stesso tipo su tutti gli archi (ad esempio, tutti float32 o tutti int).\n",
    "- Se anche solo un arco ha un tipo diverso (ad esempio `np.float64` invece di `float`), la conversione con `from_networkx()` può fallire o generare errori difficili da interpretare.\n",
    "- Questa funzione elimina ogni ambiguità e garantisce la massima compatibilità e robustezza della pipeline.\n",
    "\n",
    "`uniformate_attributes(G)` è il passaggio finale di pulizia che rende il grafo pronto per la conversione e l’uso in modelli di machine learning, evitando errori dovuti a tipi misti o dati sporchi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158da7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "\n",
    "def uniformate_attributes(G):\n",
    "    required_attrs = [\n",
    "        'length', 'lat', 'lon', 'hour',\n",
    "        'GeoZone', 'NormalizedZoneRisk', 'CrimeCount', 'risk_true'\n",
    "    ]\n",
    "\n",
    "    def safe_float(value):\n",
    "        try:\n",
    "            return float(value)\n",
    "        except (TypeError, ValueError):\n",
    "            return float('nan')\n",
    "\n",
    "    def safe_int(value):\n",
    "        try:\n",
    "            return int(value)\n",
    "        except (TypeError, ValueError):\n",
    "            return -1\n",
    "\n",
    "    for u, v, k in G.edges(keys=True):\n",
    "        edge = G[u][v][k]\n",
    "        cleaned_edge = {}\n",
    "        for attr in required_attrs:\n",
    "            value = edge.get(attr, None)\n",
    "            if attr in ['GeoZone', 'CrimeCount']:\n",
    "                cleaned_edge[attr] = safe_int(value)\n",
    "            else:\n",
    "                cleaned_edge[attr] = safe_float(value)\n",
    "        G[u][v][k].clear()\n",
    "        G[u][v][k].update(cleaned_edge)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5158eb57",
   "metadata": {},
   "source": [
    "### 7. **Aggiunta di `edge_idx`**\n",
    "\n",
    "  - Viene chiamata la funzione `uniformate_attributes(G)` per assicurarsi che tutti gli archi abbiano gli stessi attributi e dello stesso tipo.\n",
    "  - Viene aggiunto un nuovo attributo `edge_idx` a ogni arco, che rappresenta l’indice progressivo dell’arco. Questo è utile per mantenere la corrispondenza tra l’ordine degli archi nel grafo e le righe delle feature (`edge_attr`) in PyTorch Geometric.\n",
    "  - Crea anche un dizionario `edge_to_index` che permette di risalire rapidamente dall’arco all’indice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b92e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniforma gli attributi\n",
    "uniformate_attributes(G)\n",
    "\n",
    "# Aggiungi edge_idx per mantenere la corrispondenza con PyG\n",
    "edge_to_index = {}\n",
    "for i, (u, v, k) in enumerate(G.edges(keys=True)):\n",
    "    G[u][v][k]['edge_idx'] = i\n",
    "    edge_to_index[(u, v, k)] = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780160d6",
   "metadata": {},
   "source": [
    "## 8. **Conversione a PyG e Salvataggio del grafo**\n",
    "\n",
    "  - Definisce quali attributi degli archi usare come feature (`edge_attrs`).\n",
    "  - Carica il grafo già arricchito con `edge_idx`.\n",
    "  - Converte il grafo in un oggetto PyTorch Geometric (`data_pyg`) usando solo gli attributi specificati.\n",
    "  - Salva il dataset PyG su disco (`data_pyg.pt`) per un caricamento veloce nei modelli.\n",
    "  - Salva anche il grafo con gli indici degli archi (`grafo_with_idx.pkl`), utile per future associazioni tra archi e predizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929112e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Attributi da includere come edge_attr (escludi edge_idx se non ti serve per il modello)\n",
    "edge_attrs = ['length', 'lat', 'lon', 'hour', 'GeoZone', 'NormalizedZoneRisk', 'CrimeCount', 'risk_true']\n",
    "\n",
    "\n",
    "# Carica grafo completo\n",
    "with open(\"../data/grafo_with_idx.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "# Conversione a PyG\n",
    "data_pyg = from_networkx(G, group_edge_attrs=edge_attrs)\n",
    "\n",
    "# Salva dataset\n",
    "torch.save(data_pyg, \"../data/data_pyg.pt\")\n",
    "\n",
    "# Salva grafo con edge_idx incluso\n",
    "with open(\"../data/grafo_with_idx.pkl\", \"wb\") as f:\n",
    "    pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b8fe83",
   "metadata": {},
   "source": [
    "## 9. **TECNICA DI HOLDOUT + EARLY STOPPING**\n",
    "\n",
    "Questo blocco di codice applica la **tecnica di holdout** per la validazione e prepara i dati per il training di una rete neurale su grafi (GNN).\n",
    "\n",
    "### Cos’è l’holdout?\n",
    "L’**holdout** è una tecnica di validazione in cui il dataset viene suddiviso in due (o più) parti:\n",
    "- **Training set** (qui 80%): usato per addestrare il modello.\n",
    "- **Validation set** (qui 20%): usato per valutare le prestazioni del modello su dati mai visti durante l’addestramento.\n",
    "\n",
    "Questo permette di stimare la capacità del modello di generalizzare su dati nuovi e di evitare l’overfitting.\n",
    "\n",
    "### Cosa fa il codice?\n",
    "1. **Carica i dati**:  \n",
    "   `data_pyg.edge_attr` contiene tutte le feature degli archi, inclusa la variabile target (`risk_true`).\n",
    "\n",
    "2. **Separa le feature dal target**:  \n",
    "   - `data_pyg.y` prende la colonna target (rischio vero).\n",
    "   - `data_pyg.edge_attr` mantiene solo le prime 7 colonne (le vere feature di input).\n",
    "\n",
    "3. **Standardizza le feature**:  \n",
    "   - Usa `StandardScaler` per portare tutte le feature su una scala simile (media 0, deviazione standard 1).  \n",
    "   - Questo è importante per il deep learning perché aiuta la rete a convergere più velocemente e stabilmente.\n",
    "\n",
    "4. **Crea le maschere di train/validation**:  \n",
    "   - Divide gli archi in modo casuale (ma riproducibile) in 80% train e 20% validation.\n",
    "   - Crea due maschere booleane (`train_mask`, `val_mask`) che indicano quali archi usare per il training e quali per la validazione.\n",
    "\n",
    "5. **Salva le maschere nel data object**:  \n",
    "   - Queste maschere saranno usate durante il training per calcolare la loss solo sugli archi di train o validation.\n",
    "\n",
    "### Perché usare l’holdout nel deep learning (e nelle GNN)?\n",
    "- **Semplicità e velocità**: L’holdout è facile da implementare e veloce da eseguire, soprattutto su dataset grandi.\n",
    "- **Evita overfitting**: Permette di monitorare la performance su dati non visti e fermare l’addestramento quando la validazione smette di migliorare (**early stopping**).\n",
    "- **Adatto alle GNN**: Nelle reti su grafi, spesso si lavora con un solo grande grafo (non tanti piccoli), quindi la divisione in train/validation si fa a livello di archi (o nodi), non di grafi interi.\n",
    "\n",
    "### Early stopping\n",
    "- Durante il training, si monitora la loss di validazione.\n",
    "- Se la loss di validazione non migliora per un certo numero di epoche, si interrompe l’addestramento.\n",
    "- Questo previene l’overfitting e salva il modello “migliore” (quello con la loss di validazione più bassa).\n",
    "\n",
    "\n",
    "**Perché Holdout con early stopping ?**\n",
    "Si è scelto di applicare l’holdout con early stopping perché è una strategia robusta e pratica per valutare e addestrare modelli di deep learning su grafi, garantendo che il modello impari a generalizzare e non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data_pyg = torch.load(\"../data/data_pyg.pt\", weights_only=False)\n",
    "\n",
    "# Ora data_pyg.edge_attr ha shape [num_edges, 8] — tutte le features comprese 'risk_true'\n",
    "\n",
    "# Separa il target (ultima colonna) e le feature (prime 7 colonne)\n",
    "data_pyg.y = data_pyg.edge_attr[:, 7]\n",
    "data_pyg.edge_attr = data_pyg.edge_attr[:, :7]\n",
    "\n",
    "# (Opzionale) Standardizzazione delle feature\n",
    "scaler = StandardScaler()\n",
    "data_pyg.edge_attr = torch.tensor(scaler.fit_transform(data_pyg.edge_attr), dtype=torch.float)\n",
    "\n",
    "# Numero di archi\n",
    "num_edges = data_pyg.edge_attr.shape[0]\n",
    "indices = np.arange(num_edges)\n",
    "\n",
    "# 80% train, 20% validation\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "val_mask[val_idx] = True\n",
    "\n",
    "data_pyg.train_mask = train_mask\n",
    "data_pyg.val_mask = val_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995771a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_pyg.train_mask )\n",
    "print(data_pyg.val_mask)\n",
    "print(data_pyg.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf086b7f",
   "metadata": {},
   "source": [
    "## 10. **Tecnica dell'Early Stopping con Training Loop**\n",
    "\n",
    "La tecnica dell'**early stopping** è uno strumento fondamentale per prevenire l'**overfitting** nei modelli di deep learning. Viene implementata all'interno del **training loop**, ovvero il ciclo di addestramento che viene ripetuto per un certo numero di epoche.\n",
    "\n",
    "### Cos'è un training loop?\n",
    "\n",
    "Il training loop è una sequenza di operazioni che vengono eseguite per ogni **epoca** (passaggio su tutto il dataset di training). Comprende due fasi principali:\n",
    "\n",
    "### Fase di training (`model.train()`)\n",
    "\n",
    "Questa fase viene eseguita sul **training set**, ovvero i dati usati per far apprendere il modello.\n",
    "\n",
    "- `model.train()` attiva la **modalità di addestramento**: in questa modalità, componenti come i **dropout** e **batch normalization** funzionano in modo attivo e casuale, simulando situazioni diverse per migliorare la capacità del modello di generalizzare.\n",
    "- Si calcolano le **predizioni** del modello.\n",
    "- Si calcola la **loss** (funzione di costo) tra predizioni e valori reali.\n",
    "- Si esegue il **backpropagation** (`loss.backward()`): il gradiente viene calcolato per ogni parametro del modello.\n",
    "- Si aggiornano i parametri del modello con l'**ottimizzatore** (`optimizer.step()`).\n",
    "- Si azzerano i gradienti accumulati con `optimizer.zero_grad()` per evitare che si sommino tra un batch e l'altro.\n",
    "\n",
    "### Fase di validazione (`model.eval()`)\n",
    "\n",
    "Questa fase valuta il modello sul **validation set**, cioè un sottoinsieme dei dati non visto durante il training.\n",
    "\n",
    "- `model.eval()` attiva la **modalità di valutazione**: in questa modalità, dropout e batch normalization vengono disattivati o fissati, così da rendere la valutazione stabile e coerente.\n",
    "- Si fanno **predizioni** sul validation set.\n",
    "- La loss viene calcolata **senza aggiornare i pesi**. Per evitare calcoli inutili dei gradienti, si racchiude questa fase in un blocco `with torch.no_grad()`.\n",
    "\n",
    "### Monitoraggio delle performance\n",
    "\n",
    "Dopo ogni epoca:\n",
    "- Si stampa la **training loss** e la **validation loss**.\n",
    "- Se la validation loss migliora (cioè diminuisce), si salva una **copia dello stato attuale del modello** (checkpoint) e si azzera il contatore `wait`.\n",
    "- Se invece la validation loss **non migliora**, il contatore `wait` viene incrementato.\n",
    "\n",
    "---\n",
    "\n",
    "### Early Stopping\n",
    "\n",
    "L'early stopping entra in azione quando la validation loss **non migliora per un numero definito di epoche consecutive** (parametro `patience`).\n",
    "\n",
    "- Se `wait >= patience`, l'addestramento si interrompe.\n",
    "- In questo modo si evita che il modello continui ad apprendere pattern inutili o rumore presente nei dati di training, riducendo così l'**overfitting**.\n",
    "- Alla fine, si può ripristinare il **modello migliore** salvato durante l'ultima epoca con la loss minima.\n",
    "\n",
    "### Perché è importante?\n",
    "\n",
    "- **Previene l'overfitting:** interrompe l'addestramento prima che il modello inizi a \"memorizzare\" i dati.\n",
    "- **Riduce i tempi di addestramento:** si evita di sprecare tempo computazionale in epoche inutili.\n",
    "- **Conserva il modello migliore:** permette di mantenere lo stato del modello che ha ottenuto le migliori prestazioni sul validation set.\n",
    "\n",
    "- `model.train()` e `model.eval()` **non eseguono l’addestramento o la valutazione di per sé**, ma **cambiano il comportamento interno del modello** (es. attivazione/disattivazione di dropout e batch norm).\n",
    "- `torch.no_grad()` è utile per **velocizzare la validazione** e risparmiare memoria, perché evita il tracciamento del grafo computazionale.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac540ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training con early stopping...\n",
      " Epoch 001 | Train Loss: 0.0846 | Val Loss: 0.0258\n",
      " Epoch 002 | Train Loss: 0.0259 | Val Loss: 0.0348\n",
      " Epoch 003 | Train Loss: 0.0350 | Val Loss: 0.0214\n",
      " Epoch 004 | Train Loss: 0.0215 | Val Loss: 0.0171\n",
      " Epoch 005 | Train Loss: 0.0172 | Val Loss: 0.0189\n",
      " Epoch 006 | Train Loss: 0.0189 | Val Loss: 0.0204\n",
      " Epoch 007 | Train Loss: 0.0205 | Val Loss: 0.0205\n",
      " Epoch 008 | Train Loss: 0.0205 | Val Loss: 0.0193\n",
      " Epoch 009 | Train Loss: 0.0193 | Val Loss: 0.0176\n",
      " Epoch 010 | Train Loss: 0.0177 | Val Loss: 0.0163\n",
      " Epoch 011 | Train Loss: 0.0164 | Val Loss: 0.0158\n",
      " Epoch 012 | Train Loss: 0.0159 | Val Loss: 0.0163\n",
      " Epoch 013 | Train Loss: 0.0164 | Val Loss: 0.0170\n",
      " Epoch 014 | Train Loss: 0.0171 | Val Loss: 0.0172\n",
      " Epoch 015 | Train Loss: 0.0173 | Val Loss: 0.0168\n",
      " Epoch 016 | Train Loss: 0.0169 | Val Loss: 0.0161\n",
      " Epoch 017 | Train Loss: 0.0161 | Val Loss: 0.0156\n",
      " Epoch 018 | Train Loss: 0.0156 | Val Loss: 0.0154\n",
      " Epoch 019 | Train Loss: 0.0155 | Val Loss: 0.0156\n",
      " Epoch 020 | Train Loss: 0.0156 | Val Loss: 0.0158\n",
      " Epoch 021 | Train Loss: 0.0158 | Val Loss: 0.0159\n",
      " Epoch 022 | Train Loss: 0.0160 | Val Loss: 0.0159\n",
      " Epoch 023 | Train Loss: 0.0160 | Val Loss: 0.0158\n",
      " Epoch 024 | Train Loss: 0.0158 | Val Loss: 0.0156\n",
      " Epoch 025 | Train Loss: 0.0156 | Val Loss: 0.0154\n",
      " Epoch 026 | Train Loss: 0.0154 | Val Loss: 0.0153\n",
      " Epoch 027 | Train Loss: 0.0153 | Val Loss: 0.0153\n",
      " Epoch 028 | Train Loss: 0.0153 | Val Loss: 0.0153\n",
      " Epoch 029 | Train Loss: 0.0154 | Val Loss: 0.0154\n",
      " Epoch 030 | Train Loss: 0.0155 | Val Loss: 0.0154\n",
      " Epoch 031 | Train Loss: 0.0155 | Val Loss: 0.0154\n",
      " Epoch 032 | Train Loss: 0.0154 | Val Loss: 0.0152\n",
      " Epoch 033 | Train Loss: 0.0153 | Val Loss: 0.0151\n",
      " Epoch 034 | Train Loss: 0.0152 | Val Loss: 0.0151\n",
      " Epoch 035 | Train Loss: 0.0151 | Val Loss: 0.0151\n",
      " Epoch 036 | Train Loss: 0.0151 | Val Loss: 0.0151\n",
      " Epoch 037 | Train Loss: 0.0152 | Val Loss: 0.0152\n",
      " Epoch 038 | Train Loss: 0.0152 | Val Loss: 0.0152\n",
      " Epoch 039 | Train Loss: 0.0152 | Val Loss: 0.0151\n",
      " Epoch 040 | Train Loss: 0.0152 | Val Loss: 0.0151\n",
      " Epoch 041 | Train Loss: 0.0151 | Val Loss: 0.0150\n",
      " Epoch 042 | Train Loss: 0.0151 | Val Loss: 0.0150\n",
      " Epoch 043 | Train Loss: 0.0150 | Val Loss: 0.0150\n",
      " Epoch 044 | Train Loss: 0.0150 | Val Loss: 0.0150\n",
      " Epoch 045 | Train Loss: 0.0151 | Val Loss: 0.0150\n",
      " Epoch 046 | Train Loss: 0.0151 | Val Loss: 0.0150\n",
      " Epoch 047 | Train Loss: 0.0151 | Val Loss: 0.0150\n",
      " Epoch 048 | Train Loss: 0.0150 | Val Loss: 0.0150\n",
      " Epoch 049 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
      " Epoch 050 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
      " Epoch 051 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
      " Epoch 052 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
      " Epoch 053 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
      " Epoch 054 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
      " Epoch 055 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
      " Epoch 056 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
      " Epoch 057 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 058 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 059 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 060 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 061 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 062 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 063 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 064 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 065 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 066 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 067 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 068 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 069 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 070 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 071 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 072 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 073 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 074 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 075 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 076 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 077 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 078 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
      " Epoch 079 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 080 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 081 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 082 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 083 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 084 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 085 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 086 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 087 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 088 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 089 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 090 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 091 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 092 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 093 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 094 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 095 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 096 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 097 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 098 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 099 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 100 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 101 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 102 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 103 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 104 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 105 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
      " Epoch 106 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 107 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 108 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 109 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 110 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 111 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 112 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 113 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 114 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 115 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 116 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 117 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 118 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 119 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 120 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 121 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 122 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 123 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 124 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 125 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 126 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 127 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 128 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 129 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 130 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 131 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 132 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 133 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 134 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 135 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 136 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 137 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 138 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 139 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 140 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 141 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 142 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 143 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 144 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 145 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 146 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 147 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 148 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 149 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 150 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 151 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 152 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 153 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 154 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 155 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 156 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 157 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 158 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 159 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 160 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 161 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 162 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 163 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 164 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 165 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 166 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 167 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 168 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 169 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 170 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 171 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 172 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 173 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 174 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 175 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 176 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 177 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 178 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 179 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 180 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 181 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 182 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 183 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 184 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 185 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 186 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 187 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 188 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 189 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 190 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 191 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 192 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 193 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 194 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 195 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 196 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 197 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 198 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 199 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 200 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 201 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 202 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 203 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 204 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 205 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 206 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 207 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 208 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
      " Epoch 209 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 210 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 211 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 212 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 213 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 214 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 215 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 216 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 217 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 218 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 219 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 220 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 221 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 222 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 223 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 224 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 225 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 226 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 227 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 228 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 229 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 230 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 231 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 232 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 233 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 234 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 235 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 236 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 237 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 238 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 239 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 240 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 241 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 242 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 243 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 244 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 245 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 246 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 247 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 248 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 249 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 250 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 251 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 252 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 253 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 254 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
      " Epoch 255 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 256 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 257 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 258 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 259 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 260 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 261 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 262 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 263 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 264 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 265 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 266 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 267 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 268 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 269 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 270 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 271 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 272 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 273 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 274 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 275 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 276 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 277 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 278 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 279 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 280 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 281 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 282 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 283 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 284 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 285 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 286 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 287 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 288 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 289 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 290 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 291 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 292 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 293 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 294 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 295 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 296 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 297 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 298 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 299 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
      " Epoch 300 | Train Loss: 0.0147 | Val Loss: 0.0147\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class RiskGNN(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.edge_encoder = nn.Linear(in_channels, 32) #32 indica quanti neuroni nella prima hidden layer\n",
    "        self.conv1 = GCNConv(32, 64)\n",
    "        self.conv2 = GCNConv(64, 32)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        edge_feat = F.relu(self.edge_encoder(edge_attr))   # Encode edge features\n",
    "        x = self.conv1(edge_feat, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        return self.out(x).squeeze()  # Ritorna un valore per ogni arco\n",
    "\n",
    "\n",
    "device = torch.device('cpu') #uso cpu perché non ho gpu NVIDIA con cuda\n",
    "model = RiskGNN(in_channels=data_pyg.edge_attr.shape[1]).to(device)\n",
    "data_pyg = data_pyg.to(device) #eseguo in locale e non su esterni\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "wait = 0\n",
    "best_model_state = None\n",
    "best_epoch = 0\n",
    "\n",
    "print(\"Training con early stopping...\")\n",
    "\n",
    "for epoch in range(1, 301):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data_pyg.x, data_pyg.edge_index, data_pyg.edge_attr)\n",
    "    loss = criterion(out[train_mask], data_pyg.y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_out = model(data_pyg.x, data_pyg.edge_index, data_pyg.edge_attr)\n",
    "        val_loss = criterion(val_out[val_mask], data_pyg.y[val_mask])\n",
    "\n",
    "    print(f\" Epoch {epoch:03d} | Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        best_epoch = epoch\n",
    "        wait = 0\n",
    "\n",
    "        \n",
    "       \n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Early stopping a epoch {epoch}. Best epoch: {best_epoch}\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e159c8",
   "metadata": {},
   "source": [
    "## 11. **Visualizzazione dell'andamento di training e validation**\n",
    "\n",
    "Questo codice serve a **visualizzare l’andamento della loss di training e validazione** durante il training di una rete neurale, per analizzare il comportamento dell’early stopping.\n",
    "\n",
    "### Cosa fa il codice?\n",
    "\n",
    "1. **Parsing del log**  \n",
    "   - Il log contiene le righe stampate durante il training (`Epoch ... | Train Loss: ... | Val Loss: ...`).\n",
    "   - Si estraggono i valori di train loss e validation loss per ogni epoca usando una regex.\n",
    "\n",
    "2. **Stampa dei valori**  \n",
    "   - Vengono stampate le liste dei valori di train loss e val loss per verifica.\n",
    "\n",
    "3. **Individuazione della best epoch**  \n",
    "   - Si trova l’epoca in cui la validation loss è minima (`best_epoch`), che corrisponde al punto di early stopping.\n",
    "\n",
    "4. **Plot dell’andamento**  \n",
    "   - Si crea un grafico con matplotlib:\n",
    "     - Linea blu: andamento della train loss.\n",
    "     - Linea arancione: andamento della validation loss.\n",
    "     - Linea verticale rossa: epoca di early stopping (best_epoch).\n",
    "   - Si aggiungono etichette, legenda e griglia per chiarezza.\n",
    "\n",
    "### Perché è utile?\n",
    "\n",
    "- **Diagnosi del training:**  \n",
    "  Permette di vedere se il modello sta imparando (loss che scende) e se inizia a overfittare (validation loss che risale).\n",
    "- **Early stopping:**  \n",
    "  Visualizza chiaramente il punto in cui il training si sarebbe dovuto fermare per evitare overfitting.\n",
    "- **Comunicazione:**  \n",
    "  Un grafico come questo è molto utile per report, presentazioni o debugging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f763d47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Losses: [0.0846, 0.0259, 0.035, 0.0215, 0.0172, 0.0189, 0.0205, 0.0205, 0.0193, 0.0177, 0.0164, 0.0159, 0.0164, 0.0171, 0.0173, 0.0169, 0.0161, 0.0156, 0.0155, 0.0156, 0.0158, 0.016, 0.016, 0.0158, 0.0156, 0.0154, 0.0153, 0.0153, 0.0154, 0.0155, 0.0155, 0.0154, 0.0153, 0.0152, 0.0151, 0.0151, 0.0152, 0.0152, 0.0152, 0.0152, 0.0151, 0.0151, 0.015, 0.015, 0.0151, 0.0151, 0.0151, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147]\n",
      "Val Losses: [0.0258, 0.0348, 0.0214, 0.0171, 0.0189, 0.0204, 0.0205, 0.0193, 0.0176, 0.0163, 0.0158, 0.0163, 0.017, 0.0172, 0.0168, 0.0161, 0.0156, 0.0154, 0.0156, 0.0158, 0.0159, 0.0159, 0.0158, 0.0156, 0.0154, 0.0153, 0.0153, 0.0153, 0.0154, 0.0154, 0.0154, 0.0152, 0.0151, 0.0151, 0.0151, 0.0151, 0.0152, 0.0152, 0.0151, 0.0151, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#start log\n",
    "log = \"\"\"\n",
    " Training con early stopping...\n",
    " Epoch 001 | Train Loss: 0.0846 | Val Loss: 0.0258\n",
    " Epoch 002 | Train Loss: 0.0259 | Val Loss: 0.0348\n",
    " Epoch 003 | Train Loss: 0.0350 | Val Loss: 0.0214\n",
    " Epoch 004 | Train Loss: 0.0215 | Val Loss: 0.0171\n",
    " Epoch 005 | Train Loss: 0.0172 | Val Loss: 0.0189\n",
    " Epoch 006 | Train Loss: 0.0189 | Val Loss: 0.0204\n",
    " Epoch 007 | Train Loss: 0.0205 | Val Loss: 0.0205\n",
    " Epoch 008 | Train Loss: 0.0205 | Val Loss: 0.0193\n",
    " Epoch 009 | Train Loss: 0.0193 | Val Loss: 0.0176\n",
    " Epoch 010 | Train Loss: 0.0177 | Val Loss: 0.0163\n",
    " Epoch 011 | Train Loss: 0.0164 | Val Loss: 0.0158\n",
    " Epoch 012 | Train Loss: 0.0159 | Val Loss: 0.0163\n",
    " Epoch 013 | Train Loss: 0.0164 | Val Loss: 0.0170\n",
    " Epoch 014 | Train Loss: 0.0171 | Val Loss: 0.0172\n",
    " Epoch 015 | Train Loss: 0.0173 | Val Loss: 0.0168\n",
    " Epoch 016 | Train Loss: 0.0169 | Val Loss: 0.0161\n",
    " Epoch 017 | Train Loss: 0.0161 | Val Loss: 0.0156\n",
    " Epoch 018 | Train Loss: 0.0156 | Val Loss: 0.0154\n",
    " Epoch 019 | Train Loss: 0.0155 | Val Loss: 0.0156\n",
    " Epoch 020 | Train Loss: 0.0156 | Val Loss: 0.0158\n",
    " Epoch 021 | Train Loss: 0.0158 | Val Loss: 0.0159\n",
    " Epoch 022 | Train Loss: 0.0160 | Val Loss: 0.0159\n",
    " Epoch 023 | Train Loss: 0.0160 | Val Loss: 0.0158\n",
    " Epoch 024 | Train Loss: 0.0158 | Val Loss: 0.0156\n",
    " Epoch 025 | Train Loss: 0.0156 | Val Loss: 0.0154\n",
    " Epoch 026 | Train Loss: 0.0154 | Val Loss: 0.0153\n",
    " Epoch 027 | Train Loss: 0.0153 | Val Loss: 0.0153\n",
    " Epoch 028 | Train Loss: 0.0153 | Val Loss: 0.0153\n",
    " Epoch 029 | Train Loss: 0.0154 | Val Loss: 0.0154\n",
    " Epoch 030 | Train Loss: 0.0155 | Val Loss: 0.0154\n",
    " Epoch 031 | Train Loss: 0.0155 | Val Loss: 0.0154\n",
    " Epoch 032 | Train Loss: 0.0154 | Val Loss: 0.0152\n",
    " Epoch 033 | Train Loss: 0.0153 | Val Loss: 0.0151\n",
    " Epoch 034 | Train Loss: 0.0152 | Val Loss: 0.0151\n",
    " Epoch 035 | Train Loss: 0.0151 | Val Loss: 0.0151\n",
    " Epoch 036 | Train Loss: 0.0151 | Val Loss: 0.0151\n",
    " Epoch 037 | Train Loss: 0.0152 | Val Loss: 0.0152\n",
    " Epoch 038 | Train Loss: 0.0152 | Val Loss: 0.0152\n",
    " Epoch 039 | Train Loss: 0.0152 | Val Loss: 0.0151\n",
    " Epoch 040 | Train Loss: 0.0152 | Val Loss: 0.0151\n",
    " Epoch 041 | Train Loss: 0.0151 | Val Loss: 0.0150\n",
    " Epoch 042 | Train Loss: 0.0151 | Val Loss: 0.0150\n",
    " Epoch 043 | Train Loss: 0.0150 | Val Loss: 0.0150\n",
    " Epoch 044 | Train Loss: 0.0150 | Val Loss: 0.0150\n",
    " Epoch 045 | Train Loss: 0.0151 | Val Loss: 0.0150\n",
    " Epoch 046 | Train Loss: 0.0151 | Val Loss: 0.0150\n",
    " Epoch 047 | Train Loss: 0.0151 | Val Loss: 0.0150\n",
    " Epoch 048 | Train Loss: 0.0150 | Val Loss: 0.0150\n",
    " Epoch 049 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
    " Epoch 050 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
    " Epoch 051 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
    " Epoch 052 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
    " Epoch 053 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
    " Epoch 054 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
    " Epoch 055 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
    " Epoch 056 | Train Loss: 0.0150 | Val Loss: 0.0149\n",
    " Epoch 057 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 058 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 059 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 060 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 061 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 062 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 063 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 064 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 065 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 066 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 067 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 068 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 069 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 070 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 071 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 072 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 073 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 074 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 075 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 076 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 077 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 078 | Train Loss: 0.0149 | Val Loss: 0.0149\n",
    " Epoch 079 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 080 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 081 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 082 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 083 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 084 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 085 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 086 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 087 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 088 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 089 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 090 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 091 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 092 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 093 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 094 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 095 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 096 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 097 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 098 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 099 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 100 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 101 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 102 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 103 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 104 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 105 | Train Loss: 0.0149 | Val Loss: 0.0148\n",
    " Epoch 106 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 107 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 108 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 109 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 110 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 111 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 112 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 113 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 114 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 115 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 116 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 117 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 118 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 119 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 120 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 121 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 122 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 123 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 124 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 125 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 126 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 127 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 128 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 129 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 130 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 131 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 132 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 133 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 134 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 135 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 136 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 137 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 138 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 139 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 140 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 141 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 142 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 143 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 144 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 145 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 146 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 147 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 148 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 149 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 150 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 151 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 152 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 153 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 154 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 155 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 156 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 157 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 158 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 159 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 160 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 161 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 162 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 163 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 164 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 165 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 166 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 167 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 168 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 169 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 170 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 171 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 172 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 173 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 174 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 175 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 176 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 177 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 178 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 179 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 180 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 181 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 182 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 183 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 184 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 185 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 186 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 187 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 188 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 189 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 190 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 191 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 192 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 193 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 194 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 195 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 196 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 197 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 198 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 199 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 200 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 201 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 202 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 203 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 204 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 205 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 206 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 207 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 208 | Train Loss: 0.0148 | Val Loss: 0.0148\n",
    " Epoch 209 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 210 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 211 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 212 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 213 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 214 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 215 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 216 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 217 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 218 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 219 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 220 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 221 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 222 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 223 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 224 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 225 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 226 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 227 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 228 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 229 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 230 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 231 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 232 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 233 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 234 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 235 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 236 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 237 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 238 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 239 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 240 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 241 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 242 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 243 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 244 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 245 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 246 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 247 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 248 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 249 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 250 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 251 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 252 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 253 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 254 | Train Loss: 0.0148 | Val Loss: 0.0147\n",
    " Epoch 255 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 256 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 257 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 258 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 259 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 260 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 261 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 262 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 263 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 264 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 265 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 266 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 267 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 268 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 269 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 270 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 271 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 272 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 273 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 274 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 275 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 276 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 277 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 278 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 279 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 280 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 281 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 282 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 283 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 284 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 285 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 286 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 287 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 288 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 289 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 290 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 291 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 292 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 293 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 294 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 295 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 296 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 297 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 298 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 299 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    " Epoch 300 | Train Loss: 0.0147 | Val Loss: 0.0147\n",
    "\"\"\"\n",
    "\n",
    "#end log\n",
    "\n",
    "# Parsing\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for line in log.splitlines():\n",
    "    match = re.search(r\"Train Loss: ([\\d\\.]+) \\| Val Loss: ([\\d\\.]+)\", line)\n",
    "    if match:\n",
    "        train_losses.append(float(match.group(1)))\n",
    "        val_losses.append(float(match.group(2)))\n",
    "\n",
    "# Verifica\n",
    "print(\"Train Losses:\", train_losses)\n",
    "print(\"Val Losses:\", val_losses)\n",
    "\n",
    "# Plot \n",
    "best_epoch = val_losses.index(min(val_losses)) + 1  # +1 perché gli epoch partono da 1\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.axvline(x=best_epoch, color='r', linestyle='--', label=f\"Early Stop @ Epoch {best_epoch}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Andamento Loss - Train vs Validation\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6320df1f",
   "metadata": {},
   "source": [
    "**Blocco: Caricamento modello e best epoch**\n",
    "\n",
    "- Carica il checkpoint salvato (`training_phase1_checkpoint.pth`) che contiene:\n",
    "  - I pesi migliori del modello (`model_state_dict`)\n",
    "  - L’epoca migliore raggiunta (`best_epoch`)\n",
    "  - Lo scaler usato per la standardizzazione (opzionale)\n",
    "- Stampa l’epoca migliore trovata durante il training.\n",
    "- Ricrea l’istanza del modello (`RiskGNN`) e carica i pesi migliori per poter fare predizioni o ulteriori addestramenti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c9c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint salvato in ../data/training_phase1_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    " # Salva modello e metadati\n",
    "torch.save({\n",
    "    'model_state_dict': best_model_state,\n",
    "    'best_epoch': best_epoch,\n",
    "    'scaler': scaler  # opzionale se standardizzi le feature\n",
    "}, \"../data/training_phase1_checkpoint.pth\")\n",
    "\n",
    "print(\"Checkpoint salvato in ../data/training_phase1_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f3452c",
   "metadata": {},
   "source": [
    "Carica il modello e la BEST_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb65a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carica modello e best_epoch\n",
    "checkpoint = torch.load(\"../data/training_phase1_checkpoint.pth\",weights_only=False) #modello salvato con la best epoch del odello iniziato ma nonn lamigliore\n",
    "best_epoch = checkpoint['best_epoch']\n",
    "print(f\"Best epoch: {best_epoch}\")\n",
    "best_model_state = checkpoint['model_state_dict']\n",
    "\n",
    "\n",
    "# Reinizializza modello e carica i pesi migliori\n",
    "final_model = RiskGNN(in_channels=data_pyg.edge_attr.shape[1]).to(device)\n",
    "final_model.load_state_dict(best_model_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a1104",
   "metadata": {},
   "source": [
    "## 12. **Riaddestramento Finale su Tutti i Dati**\n",
    "\n",
    "### Cos'è il riaddestramento finale?\n",
    "\n",
    "Dopo aver usato una **procedura di early stopping** per trovare il numero ottimale di epoche (`best_epoch`), si può eseguire un nuovo addestramento del modello utilizzando **tutti i dati disponibili**, incluse le porzioni che prima erano destinate alla validazione.\n",
    "\n",
    "### Cosa fa esattamente questo passaggio?\n",
    "\n",
    "1. **Estensione del training set**  \n",
    "   - Tutti gli archi (o nodi, a seconda del task) vengono inclusi nel training set: si imposta `train_mask = True` per l'intero grafo.\n",
    "   - In questo modo, il modello ha accesso a **tutte le informazioni** del dataset per imparare.\n",
    "\n",
    "2. **Reinizializzazione del modello e dell'ottimizzatore**  \n",
    "   - Si crea un nuovo modello (`final_model`) con la stessa architettura.\n",
    "   - L'ottimizzatore viene ricreato da zero, azzerando i gradienti precedenti.\n",
    "\n",
    "3. **Retrain per un numero controllato di epoche**  \n",
    "   - Il modello viene riaddestrato per esattamente `best_epoch` epoche (ottenute dalla fase di early stopping).\n",
    "   - Non viene più usata la validazione: si allena solo sul training set esteso.\n",
    "\n",
    "4. **Logging e salvataggio**  \n",
    "   - La loss viene stampata ogni 10 epoche e all'ultima epoca per tracciare l’andamento.\n",
    "   - Al termine, si salvano:\n",
    "     - I **pesi del modello** (`.pth`): utili per caricare solo i parametri.\n",
    "     - Il **modello completo** (inclusa architettura e stato): utile per il riutilizzo diretto.\n",
    "\n",
    "### Perché è importante?\n",
    "\n",
    "- **Sfrutta tutti i dati disponibili**  \n",
    "  Dopo aver trovato il numero ottimale di epoche, ha senso permettere al modello di apprendere anche dai dati che prima erano riservati alla validazione.\n",
    "\n",
    "- **Migliora la generalizzazione**  \n",
    "  Più dati vuol dire migliori stime dei pesi e una capacità maggiore di cogliere pattern utili.\n",
    "\n",
    "- **Garantisce la riproducibilità**  \n",
    "  Salvando sia i pesi che l'intero modello, si può:\n",
    "  - Riusare il modello per predizioni future.\n",
    "  - Condividere il modello con altri.\n",
    "  - Ricaricarlo per ulteriori analisi o tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrain finale su tutto il dataset per 209 epoche...\n",
      "Epoch 010 | Loss: 0.0195\n",
      "Epoch 020 | Loss: 0.0161\n",
      "Epoch 030 | Loss: 0.0155\n",
      "Epoch 040 | Loss: 0.0152\n",
      "Epoch 050 | Loss: 0.0151\n",
      "Epoch 060 | Loss: 0.0150\n",
      "Epoch 070 | Loss: 0.0149\n",
      "Epoch 080 | Loss: 0.0149\n",
      "Epoch 090 | Loss: 0.0149\n",
      "Epoch 100 | Loss: 0.0149\n",
      "Epoch 110 | Loss: 0.0149\n",
      "Epoch 120 | Loss: 0.0149\n",
      "Epoch 130 | Loss: 0.0148\n",
      "Epoch 140 | Loss: 0.0148\n",
      "Epoch 150 | Loss: 0.0148\n",
      "Epoch 160 | Loss: 0.0148\n",
      "Epoch 170 | Loss: 0.0148\n",
      "Epoch 180 | Loss: 0.0148\n",
      "Epoch 190 | Loss: 0.0148\n",
      "Epoch 200 | Loss: 0.0148\n",
      "Epoch 209 | Loss: 0.0148\n"
     ]
    }
   ],
   "source": [
    "# Unifica tutti gli archi per riaddestramento finale\n",
    "data_pyg.train_mask[:] = True\n",
    "\n",
    "# Reinizializza modello\n",
    "final_model = RiskGNN(in_channels=data_pyg.edge_attr.shape[1]).to(device)\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# Retrain per best_epoch epoche\n",
    "print(f\" Retrain finale su tutto il dataset per {best_epoch} epoche...\") #best epoch -> intorno a 176\n",
    "for epoch in range(1, best_epoch + 1):\n",
    "    final_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = final_model(data_pyg.x, data_pyg.edge_index, data_pyg.edge_attr)\n",
    "    loss = criterion(out[data_pyg.train_mask], data_pyg.y[data_pyg.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0 or epoch == best_epoch:\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "#SALVO IL MODELLO FINALE RIADDESTRATO\n",
    "torch.save(final_model.state_dict(), \"../data/final_model_weights.pth\")\n",
    "\n",
    "# Salva tutto il modello (non solo i pesi)\n",
    "torch.save(final_model, \"../data/final_model_alldata.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6dba38",
   "metadata": {},
   "source": [
    "final_model_weights.pth contiene solo i pesi (state_dict) del modello;\n",
    "\n",
    "Quando vuoi riutilizzarli, devi ricreare l’istanza del modello con la stessa architettura (RiskGNN) e poi fare load_state_dict(...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00cd7fd",
   "metadata": {},
   "source": [
    "## 13. **Predizione Aggiornata**\n",
    "\n",
    "### Assegnazione delle Predizioni agli Archi del Grafo\n",
    "\n",
    "Questo blocco di codice esegue la **predizione del rischio** su ogni arco di un grafo stradale, utilizzando un modello PyTorch Geometric già addestrato, e **salva il grafo aggiornato** con i valori predetti.\n",
    "\n",
    "### Ricaricamento del grafo\n",
    "\n",
    "Viene caricato un grafo salvato precedentemente in formato pickle (`grafo_with_idx.pkl`). Questo grafo contiene, tra le informazioni associate agli archi, anche un campo `'edge_idx'`, che collega ogni arco a un indice nel tensore degli archi del modello PyG.\n",
    "\n",
    "### Predizione con il modello finale\n",
    "\n",
    "- Il modello (`final_model`) viene messo in modalità **valutazione** con `eval()`, disattivando dropout e batch normalization per garantire predizioni stabili.\n",
    "- Si disattiva il calcolo dei gradienti con `torch.no_grad()`, per risparmiare memoria e velocizzare il processo.\n",
    "- Si eseguono le predizioni su **tutti gli archi** del grafo (`data_pyg.edge_index` e `data_pyg.edge_attr`) e si ottiene un array NumPy contenente i valori predetti (`y_pred`), uno per ogni arco.\n",
    "\n",
    "### Associazione delle predizioni agli archi\n",
    "\n",
    "- Per ogni arco `(u, v, k)` del grafo:\n",
    "  - Si recupera l’indice `edge_idx` (precalcolato e salvato in precedenza).\n",
    "  - Se presente, si assegna la predizione corrispondente `y_pred[idx]` al campo `'risk_pred'` dell’arco.\n",
    "  - Questo collega correttamente l’output del modello all’arco corrispondente nel grafo.\n",
    "\n",
    "---\n",
    "\n",
    "### Salvataggio del grafo aggiornato\n",
    "\n",
    "Infine, il grafo aggiornato con i valori di rischio predetti (`risk_pred`) viene salvato in un nuovo file (`grafo_with_preds.pkl`), pronto per essere visualizzato o analizzato.\n",
    "\n",
    "---\n",
    "\n",
    "### Servirà poi per...\n",
    "\n",
    "Questo passaggio è essenziale quando si vogliono:\n",
    "- Visualizzare le **zone di rischio** su una mappa.\n",
    "- Usare le predizioni del modello per **analisi successive** o per prendere decisioni (es. pianificare percorsi sicuri).\n",
    "- Collegare le predizioni numeriche del modello ai **dati geografici reali** del grafo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb735e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Ricarica grafo con edge_idx già salvati\n",
    "with open(\"../data/grafo_with_idx.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "    \n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = final_model(data_pyg.x, data_pyg.edge_index, data_pyg.edge_attr).cpu().numpy()\n",
    "\n",
    "\n",
    "# Associa predizioni all'arco corretto via edge_idx\n",
    "for u, v, k in G.edges(keys=True):\n",
    "    idx = G[u][v][k].get('edge_idx', None)\n",
    "    if idx is not None:\n",
    "        G[u][v][k]['risk_pred'] = float(y_pred[idx])\n",
    "\n",
    "with open(\"../data/grafo_with_preds.pkl\", \"wb\") as f:\n",
    "    pickle.dump(G, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee199b",
   "metadata": {},
   "source": [
    "## 14. **Calcolo del percorso sicuro senza geometry**\n",
    "\n",
    "**Funzione: `calcola_percorso_sicuro`**\n",
    "\n",
    "- **Carica il grafo**:  \n",
    "  Apre il file pickle del grafo già addestrato e arricchito con le predizioni di rischio (`risk_pred`).\n",
    "\n",
    "- **Ripristina coordinate nodi**:  \n",
    "  Per ogni arco, copia latitudine e longitudine dagli attributi dell’arco ai nodi estremi (`x` e `y`). Questo è necessario perché alcune funzioni di OSMnx e NetworkX richiedono che i nodi abbiano coordinate per il pathfinding.\n",
    "\n",
    "- **Geocoding degli indirizzi**:  \n",
    "  Usa Nominatim per convertire gli indirizzi di partenza e arrivo in coordinate geografiche (latitudine, longitudine).\n",
    "\n",
    "- **Trova i nodi più vicini**:  \n",
    "  Identifica nel grafo i nodi più vicini alle coordinate di partenza e arrivo, così da poterli usare come estremi del percorso.\n",
    "\n",
    "- **Controllo rischio sugli archi**:  \n",
    "  Estrae tutti i valori di rischio predetto dagli archi e stampa statistiche (min, max, media) per informare l’utente sul range di rischio nel grafo.\n",
    "\n",
    "- **Definisce euristica per A\\***:  \n",
    "  Implementa una funzione euristica per l’algoritmo A* basata sulla distanza geodetica (great-circle) tra due nodi, per rendere la ricerca del percorso efficiente.\n",
    "\n",
    "- **Calcola percorso a rischio minimo**:  \n",
    "  Usa l’algoritmo A* per trovare il percorso tra partenza e arrivo che minimizza la somma dei rischi predetti (`risk_true`) sugli archi attraversati. Se non esiste un percorso, solleva un errore.\n",
    "\n",
    "- **Restituisce le coordinate del percorso**:  \n",
    "  Ritorna la lista di coordinate (latitudine, longitudine) dei nodi che compongono il percorso trovato.\n",
    "\n",
    "**Perché è importante:**  \n",
    "Questa funzione permette di calcolare in modo automatico il percorso pedonale più sicuro tra due indirizzi, sfruttando le predizioni del modello GNN e integrando dati reali di rischio. È il cuore dell’applicazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21439f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import great_circle\n",
    "import osmnx as ox\n",
    "\n",
    "def calcola_percorso_sicuro(indirizzo_partenza: str, indirizzo_arrivo: str, grafo_path=\"../data/grafo_with_preds.pkl\"):\n",
    "    # === Carica il grafo già addestrato ===\n",
    "    with open(grafo_path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "\n",
    "    # === Ripristina temporaneamente x/y per nodi (necessario per pathfinding)\n",
    "    for u, v, k in G.edges(keys=True):\n",
    "        lat = G[u][v][k].get(\"lat\")\n",
    "        lon = G[u][v][k].get(\"lon\")\n",
    "        if lat is not None and lon is not None:\n",
    "            for n in (u, v):\n",
    "                G.nodes[n]['x'] = lon\n",
    "                G.nodes[n]['y'] = lat\n",
    "\n",
    "    # === Geocoding partenza e arrivo ===\n",
    "    geolocator = Nominatim(user_agent=\"percorso_sicuro_gnn\")\n",
    "    loc_partenza = geolocator.geocode(indirizzo_partenza)\n",
    "    loc_arrivo = geolocator.geocode(indirizzo_arrivo)\n",
    "\n",
    "    if not loc_partenza or not loc_arrivo:\n",
    "        raise ValueError(\"❌ Indirizzi non trovati.\")\n",
    "\n",
    "    coord_partenza = (loc_partenza.latitude, loc_partenza.longitude)\n",
    "    coord_arrivo = (loc_arrivo.latitude, loc_arrivo.longitude)\n",
    "\n",
    "    # === Trova i nodi più vicini nel grafo G ===\n",
    "    nodo_partenza = ox.distance.nearest_nodes(G, coord_partenza[1], coord_partenza[0])\n",
    "    nodo_arrivo = ox.distance.nearest_nodes(G, coord_arrivo[1], coord_arrivo[0])\n",
    "\n",
    "    # === Verifica rischio medio sugli archi ===\n",
    "    valori_rischio = [d.get('risk_pred') for _, _, d in G.edges(data=True) if 'risk_pred' in d]\n",
    "    if not valori_rischio:\n",
    "        raise ValueError(\"❌ Nessun valore 'risk_true' trovato negli archi del grafo!\")\n",
    "\n",
    "    print(f\"📊 Rischio predetto (min): {min(valori_rischio):.4f}\")\n",
    "    print(f\"📊 Rischio predetto (max): {max(valori_rischio):.4f}\")\n",
    "    print(f\"📊 Rischio predetto (media): {sum(valori_rischio)/len(valori_rischio):.4f}\")\n",
    "\n",
    "    # === Heuristica per A* (distanza geodetica) ===\n",
    "    def heuristic(u, v):\n",
    "        c1 = (G.nodes[u]['y'], G.nodes[u]['x'])\n",
    "        c2 = (G.nodes[v]['y'], G.nodes[v]['x'])\n",
    "        return great_circle(c1, c2).meters\n",
    "\n",
    "    # === Calcola percorso minimo rischio ===\n",
    "    try:\n",
    "        percorso = nx.astar_path(G, nodo_partenza, nodo_arrivo, weight='risk_true', heuristic=heuristic)\n",
    "        print(\"✅ Percorso calcolato con rischio predetto GNN.\")\n",
    "    except nx.NetworkXNoPath:\n",
    "        raise ValueError(\"❌ Nessun percorso sicuro trovato.\")\n",
    "\n",
    "    # === Coordinate percorso ===\n",
    "    route_coords = [(G.nodes[n]['y'], G.nodes[n]['x']) for n in percorso]\n",
    "    return route_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e33e456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Rischio predetto (min): 0.2493\n",
      "📊 Rischio predetto (max): 0.6556\n",
      "📊 Rischio predetto (media): 0.3440\n",
      "✅ Percorso calcolato con rischio predetto GNN.\n",
      "41.906238, -87.662149\n",
      "41.906109, -87.662117\n",
      "41.905721, -87.662583\n",
      "✅ Percorso salvato in percorso_sicuro.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "indirizzo_from = \"W Evergreen Ave, Chicago\"\n",
    "indirizzo_to = \"N Noble St, Chicago\"\n",
    "percorso = calcola_percorso_sicuro(indirizzo_from, indirizzo_to)\n",
    "for lat, lon in percorso:\n",
    "    print(f\"{lat:.6f}, {lon:.6f}\")\n",
    "\n",
    "\n",
    "# Salva il percorso come lista di coordinate in JSON\n",
    "with open(\"../data/percorso_sicuro.json\", \"w\") as f:\n",
    "    json.dump(percorso, f)\n",
    "\n",
    "print(\"✅ Percorso salvato in percorso_sicuro.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859068f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio\n",
    "with open(\"percorso_sicuro.pkl\", \"wb\") as f:\n",
    "    pickle.dump(percorso, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0717088c",
   "metadata": {},
   "source": [
    "**ALCUNI PLOT DI ALCUNE INFORMAZIONI PER VEDERE FUNZIONAMENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bf38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Estrai tutti i valori risk_pred dagli archi\n",
    "valori_rischio = [\n",
    "    d.get('risk_pred', None)\n",
    "    for _, _, _, d in G.edges(keys=True, data=True)\n",
    "    if 'risk_pred' in d\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(valori_rischio, bins=30, color='orange', edgecolor='black')\n",
    "plt.title(\"Distribuzione dei valori di rischio predetto\")\n",
    "plt.xlabel(\"Rischio predetto (risk_true)\")\n",
    "plt.ylabel(\"Numero di archi\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "valori_rischio = [d.get('risk_pred', None) for _, _, _, d in G.edges(keys=True, data=True)]\n",
    "print(f\"Numero archi con rischio stimato: {sum(r is not None for r in valori_rischio)}\")\n",
    "print(f\"Range valori rischio: min={min(valori_rischio):.2f}, max={max(valori_rischio):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e463be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_risk = sum(G[u][v][k]['risk_true'] for u, v, k in zip(percorso[:-1], percorso[1:], [0]*len(percorso[:-1])))\n",
    "print(f\"🔎 Rischio totale del percorso: {total_risk:.3f}\")\n",
    "\n",
    "\n",
    "path_length = len(percorso)\n",
    "max_risk = path_length * max(valori_rischio)\n",
    "rischio_percentuale = total_risk / max_risk * 100\n",
    "\n",
    "print(f\" Lunghezza percorso: {path_length} archi\")\n",
    "print(f\" Rischio massimo teorico: {max_risk:.2f}\")\n",
    "print(f\" Percentuale rischio percorso: {rischio_percentuale:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b9d0d",
   "metadata": {},
   "source": [
    "Poiché non ho aggiunto all inizio geometry per creare linee piu complicate tra un nodo A e un nodo B lo aggiungo ora creando una copia di grafo_with_idx e la sua copia la chiamo grafo_with_geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294e59a",
   "metadata": {},
   "source": [
    "## 15. **Aggiunta delle Geometrie al Grafo con Predizioni di Rischio**\n",
    "\n",
    "### Problema da risolvere\n",
    "Durante la fase iniziale di creazione del grafo, **non sono state incluse le geometrie degli archi**. Questo significa che ogni arco viene rappresentato come una semplice linea retta tra due nodi, perdendo completamente la forma reale delle strade (curve, svolte, incroci complessi).\n",
    "\n",
    "### Perché servono le geometrie?\n",
    "- **Rappresentazione realistica**: Le strade reali raramente sono linee perfettamente dritte tra due punti\n",
    "- **Visualizzazioni accurate**: Per creare mappe che rispecchiano la topologia urbana effettiva\n",
    "- **Calcoli di distanza precisi**: Per misurazioni più accurate della lunghezza degli archi\n",
    "- **Compatibilità con strumenti GIS**: Per l'integrazione con software di mapping avanzati\n",
    "\n",
    "### Cosa viene fatto\n",
    "Questo processo arricchisce il grafo addestrato (che contiene tutte le predizioni di rischio) con le informazioni geometriche originali provenienti da OpenStreetMap.\n",
    "\n",
    "**Ricreazione del grafo base**: Si scarica nuovamente il grafo stradale di Chicago da OSMnx, che include automaticamente le geometrie complete degli archi.\n",
    "\n",
    "**Caricamento del grafo addestrato**: Si ricarica il grafo che contiene tutte le predizioni di rischio e le feature calcolate dal modello GNN.\n",
    "\n",
    "**Trasferimento delle geometrie**: Per ogni arco presente in entrambi i grafi, si copia l'attributo `geometry` dal grafo OSM al grafo addestrato. Questo preserva tutte le predizioni esistenti aggiungendo solo l'informazione geometrica.\n",
    "\n",
    "**Salvataggio del grafo arricchito**: Si crea una nuova versione del grafo (`grafo_copy_with_geometry.pkl`) che combina:\n",
    "- Tutte le predizioni di rischio del modello addestrato\n",
    "- Le geometrie reali delle strade da OpenStreetMap\n",
    "\n",
    "### Vantaggi dell'approccio\n",
    "- **Conservazione del lavoro svolto**: Non si perdono le predizioni del modello GNN\n",
    "- **Miglioramento visivo**: Le visualizzazioni diventano più realistiche e comprensibili\n",
    "- **Flessibilità d'uso**: Il grafo può essere utilizzato sia per calcoli che per presentazioni\n",
    "- **Compatibilità estesa**: Supporta l'uso con librerie di mapping interattive come Folium\n",
    "\n",
    "### Risultato finale\n",
    "Il grafo risultante mantiene tutte le capacità predittive originali ma può ora essere utilizzato per creare:\n",
    "- Mappe interattive che seguono le curve reali delle strade\n",
    "- Visualizzazioni più precise dei percorsi sicuri\n",
    "- Rappresentazioni fedeli della rete stradale urbana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a22f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import pickle\n",
    "\n",
    "# 1. Ricrea grafo base da OSMnx (geometry già inclusa!)\n",
    "G_osm = ox.graph_from_place(\"Chicago, Illinois, USA\", network_type='walk')\n",
    "\n",
    "# 2. Carica il tuo grafo addestrato\n",
    "with open(\"../data/grafo_with_preds.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "# 3. Copia geometry se esiste da grafo OSM\n",
    "for u, v, k, data in G.edges(keys=True, data=True):\n",
    "    if G_osm.has_edge(u, v, k):\n",
    "        data_osm = G_osm[u][v][k]\n",
    "        if 'geometry' in data_osm:\n",
    "            data['geometry'] = data_osm['geometry']\n",
    "\n",
    "# 4. Salva nuova versione del grafo con geometrie\n",
    "with open(\"../data/grafo_copy_with_geometry.pkl\", \"wb\") as f:\n",
    "    pickle.dump(G, f)\n",
    "\n",
    "print(\"Grafo salvato con geometrie in: grafo_copy_with_geometry.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f669e44a",
   "metadata": {},
   "source": [
    "## 16. **Visualizzazione di un Percorso Sicuro sulla Mappa**\n",
    "\n",
    "Questa funzione visualizza un percorso calcolato su una mappa interattiva Folium, evidenziandolo con una linea blu e indicando partenza e arrivo con marker colorati. È utile per mostrare graficamente un tragitto \"sicuro\", ad esempio calcolato da un algoritmo di routing.\n",
    "\n",
    "### Caricamento del grafo\n",
    "\n",
    "- Il grafo stradale (ad esempio ottenuto con `osmnx`) viene caricato da un file `.pkl`.\n",
    "- Sebbene in questa funzione il grafo non venga usato direttamente per disegnare archi o nodi, è necessario per mantenere coerenza con altre funzioni o per usi futuri.\n",
    "\n",
    "\n",
    "### Caricamento del percorso\n",
    "\n",
    "- Il percorso viene caricato da un file `.json` che contiene una lista ordinata di coordinate `(latitudine, longitudine)`.\n",
    "- Ogni punto rappresenta una tappa del tragitto sicuro.\n",
    "\n",
    "\n",
    "### Creazione della mappa\n",
    "\n",
    "- La mappa viene centrata nel punto medio del percorso, calcolando la media delle coordinate.\n",
    "- Si imposta un livello di zoom appropriato (`zoom_start=15`) per una visione dettagliata del percorso urbano.\n",
    "- Viene utilizzato il tema `\"CartoDB.Positron\"` per fornire uno sfondo leggibile e chiaro.\n",
    "\n",
    "\n",
    "### Visualizzazione del percorso\n",
    "\n",
    "- Le coordinate del percorso vengono convertite in una geometria `LineString`.\n",
    "- Viene disegnata una **linea blu** spessa (`weight=5`) che rappresenta il percorso sicuro.\n",
    "- La linea è interattiva: al passaggio del mouse appare un tooltip con la scritta `\"Percorso Sicuro\"`.\n",
    "\n",
    "\n",
    "### Marker di partenza e arrivo\n",
    "\n",
    "- Viene inserito un **marker azzurro** per indicare il punto di partenza, con icona `\"play\"` e popup contenente l'indirizzo di partenza.\n",
    "- Viene inserito un **marker rosa** per indicare il punto di arrivo, con icona `\"flag\"` e popup contenente l'indirizzo di arrivo.\n",
    "- Questi marker aiutano a distinguere chiaramente l’inizio e la fine del percorso.\n",
    "\n",
    "### Integrazione del modulo di feedback\n",
    "- Al termine del percorso, viene aggiunto un **marker verde** che contiene un collegamento diretto a un modulo di feedback, implementato tramite Google Forms.\n",
    "- Questo link permette agli utenti di fornire una **valutazione del livello di sicurezza percepito** lungo il percorso suggerito e di lasciare eventuali segnalazioni o suggerimenti.\n",
    "- Il link viene visualizzato all'interno di un **Popup HTML cliccabile**, che si apre in una nuova scheda del browser.\n",
    "- Questa integrazione consente **una raccolta feedback immediata e contestuale**, migliorando la qualità dei dati raccolti e coinvolgendo direttamente l’utente finale\n",
    "\n",
    "### Output della funzione\n",
    "\n",
    "- La funzione restituisce l’oggetto `folium.Map`, che può essere visualizzato direttamente nel notebook.\n",
    "- Il risultato è una mappa interattiva che mostra in modo chiaro e intuitivo il percorso calcolato tra due punti.\n",
    "- Raccogliere opinioni e segnalazioni direttamente dagli utenti, integrando la componente partecipativa nella valutazione della sicurezza urbana.\n",
    "\n",
    "### Utilizzo pratico\n",
    "\n",
    "Questa funzione è particolarmente utile per:\n",
    "- Visualizzare il risultato di un algoritmo di routing (es. percorso più sicuro).\n",
    "- Mostrare un tragitto personalizzato su mappa.\n",
    "- Includere il percorso in applicazioni geografiche, dashboard o report interattivi.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b198f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import json\n",
    "import pickle\n",
    "from shapely.geometry import LineString\n",
    "from branca.colormap import LinearColormap\n",
    "\n",
    "def visualizza_percorso_con_geometry(\n",
    "    grafo_path: str,\n",
    "    percorso_json_path: str,\n",
    "    indirizzo_partenza: str,\n",
    "    indirizzo_arrivo: str\n",
    "):\n",
    "    # === Carica il grafo\n",
    "    with open(grafo_path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "\n",
    "    # === Carica il percorso calcolato\n",
    "    with open(percorso_json_path, \"r\") as f:\n",
    "        percorso = json.load(f)  # lista di (lat, lon)\n",
    "\n",
    "    # === Mappa centrata a metà percorso\n",
    "    lat_centro = sum(p[0] for p in percorso) / len(percorso)\n",
    "    lon_centro = sum(p[1] for p in percorso) / len(percorso)\n",
    "    m = folium.Map(location=[lat_centro, lon_centro], zoom_start=15, tiles='CartoDB.Positron')\n",
    "\n",
    "    # === Traccia il percorso come una LineString (blu)\n",
    "    line = LineString([(lon, lat) for lat, lon in percorso])\n",
    "    folium.PolyLine(\n",
    "        locations=[(lat, lon) for lon, lat in line.coords],\n",
    "        color=\"blue\",\n",
    "        weight=5,\n",
    "        tooltip=\"Percorso Sicuro\"\n",
    "    ).add_to(m)\n",
    "\n",
    "    # === Marker partenza e arrivo\n",
    "    folium.Marker(\n",
    "        location=percorso[0],\n",
    "        popup=f\"Partenza: {indirizzo_partenza}\",\n",
    "        icon=folium.Icon(color='lightblue', icon='play')\n",
    "    ).add_to(m)\n",
    "\n",
    "    folium.Marker(\n",
    "        location=percorso[-1],\n",
    "        popup=f\"Arrivo: {indirizzo_arrivo}\",\n",
    "        icon=folium.Icon(color='pink', icon='flag')\n",
    "    ).add_to(m)\n",
    "\n",
    "    folium.Marker(\n",
    "    location=percorso[-1],\n",
    "    popup=folium.Popup(\n",
    "        '<iframe src=\"https://docs.google.com/forms/d/e/1FAIpQLScqGwU9y5Pjkwlq-806Q4U5mr4PtpyFI0KRK6UuNmTd9Wy9IA/viewform?embedded=true\" width=\"640\" height=\"976\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Caricamento…</iframe>',\n",
    "        max_width=250\n",
    "    ),\n",
    "    icon=folium.Icon(color='green', icon='info-sign')\n",
    "    ).add_to(m)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COPIA DEL CODICE PER AVVIARE LA FUNZIONE CALCOLA_PERCORSO_SICURO IN MODO DA RUNNARE ALL'OCCORRENZA QUESTA PARTE PER CALCOLARE IL PERCORSO  E QUELLA DI SOTTO PER LA VISUALIZZAZIONE DEL PERCORSO\n",
    "\n",
    "import json\n",
    "\n",
    "indirizzo_from = \"W Evergreen Ave, Chicago\"\n",
    "indirizzo_to = \"N Noble St, Chicago\"\n",
    "percorso = calcola_percorso_sicuro(indirizzo_from, indirizzo_to)\n",
    "for lat, lon in percorso:\n",
    "    print(f\"{lat:.6f}, {lon:.6f}\")\n",
    "\n",
    "\n",
    "# Salva il percorso come lista di coordinate in JSON\n",
    "with open(\"../data/percorso_sicuro.json\", \"w\") as f:\n",
    "    json.dump(percorso, f)\n",
    "\n",
    "print(\"✅ Percorso salvato in percorso_sicuro.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ee272",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappa_percorso = visualizza_percorso_con_geometry(\n",
    "    grafo_path=\"../data/grafo_copy_with_geometry.pkl\",\n",
    "    percorso_json_path=\"../data/percorso_sicuro.json\",\n",
    "    indirizzo_partenza= indirizzo_from,\n",
    "    indirizzo_arrivo= indirizzo_to\n",
    ")\n",
    "mappa_percorso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ecd62f",
   "metadata": {},
   "source": [
    "### Risultato -> Un esempio di percorso da due zone della città\n",
    "![Un esempio di percorso da due zone della città: ](../images/path.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d504f",
   "metadata": {},
   "source": [
    "### Questionario per raccogliere il feedback di funzionamento\n",
    "![Un esempio di percorso da due zone della città: ](../images/feedback.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3940fed1",
   "metadata": {},
   "source": [
    "## 17. **Visualizzazione delle Zone di Rischio sul Grafo Stradale**\n",
    "\n",
    "Questa funzione crea una mappa interattiva utilizzando **Folium**, in cui gli archi (strade) del grafo vengono colorati in base al livello di **rischio predetto** (`risk_pred`). È uno strumento utile per rappresentare visivamente il grado di sicurezza di una rete stradale.\n",
    "\n",
    "### Caricamento del grafo\n",
    "\n",
    "- Il grafo stradale viene caricato da un file `.pkl` (serializzato con `pickle`).\n",
    "- Si assume che ogni arco del grafo contenga:\n",
    "  - Una geometria (`data['geometry']`) in formato `shapely.LineString`, che rappresenta la forma della strada.\n",
    "  - Un valore numerico `risk_pred` tra 0 e 1, che rappresenta il livello di rischio stimato per quell’arco.\n",
    "\n",
    "\n",
    "### Inizializzazione della mappa\n",
    "\n",
    "- La mappa viene centrata su **Chicago**, con coordinate `[41.8781, -87.6298]` e livello di zoom 12.\n",
    "- Viene utilizzato il tema `\"CartoDB.Positron\"` per uno sfondo neutro e leggibile, ideale per sovrapporre dati colorati.\n",
    "\n",
    "\n",
    "### Definizione della colormap\n",
    "\n",
    "- Si definisce una **colormap continua** con:\n",
    "  - **Verde** per rischio basso (0)\n",
    "  - **Giallo** per rischio medio (0.5)\n",
    "  - **Rosso** per rischio alto (1)\n",
    "- Questa mappa di colori viene aggiunta alla mappa come **legenda**, con didascalia `\"Rischio Predetto (risk_pred)\"`.\n",
    "\n",
    "\n",
    "### Aggiunta degli archi alla mappa\n",
    "\n",
    "- Si itera su tutti gli archi del grafo.\n",
    "- Per ciascun arco che contiene sia la geometria che il valore di rischio:\n",
    "  - Si estraggono le coordinate dalla geometria e si trasformano da `(lon, lat)` a `(lat, lon)` per essere compatibili con Folium.\n",
    "  - Si disegna una **linea colorata** con:\n",
    "    - Colore calcolato dalla colormap in base a `risk_pred`.\n",
    "    - Spessore = 2\n",
    "    - Opacità = 0.7\n",
    "\n",
    "### Output della funzione\n",
    "\n",
    "- La funzione restituisce una mappa interattiva (`folium.Map`) in cui ogni arco è colorato in base al rischio stimato.\n",
    "- La mappa può essere visualizzata direttamente nel notebook oppure salvata come file HTML.\n",
    "\n",
    "### Utilizzo pratico\n",
    "\n",
    "Questa funzione è utile per:\n",
    "- Analizzare **visivamente la distribuzione del rischio** su una rete stradale urbana.\n",
    "- Supportare decisioni sulla **sicurezza urbana**, pianificazione del traffico o dei percorsi pedonali/ciclabili.\n",
    "- Integrare le informazioni predette da un modello di machine learning in un contesto geografico reale.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "273976eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizza_zone_di_rischio(grafo_path: str):\n",
    "    import folium\n",
    "    import pickle\n",
    "    from branca.colormap import LinearColormap\n",
    "\n",
    "    # === Carica il grafo\n",
    "    with open(grafo_path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "\n",
    "    # === Mappa centrata su Chicago\n",
    "    m = folium.Map(location=[41.8781, -87.6298], zoom_start=12, tiles='CartoDB.Positron')\n",
    "\n",
    "    # === Colormap per il rischio\n",
    "    colormap = LinearColormap(\n",
    "        colors=['green', 'yellow', 'red'],\n",
    "        vmin=0.28, vmax=0.45,\n",
    "        caption='Rischio Predetto (risk_pred)'\n",
    "    )\n",
    "    m.add_child(colormap)\n",
    "\n",
    "    # === Aggiungi archi con colorazione\n",
    "    for u, v, k, data in G.edges(keys=True, data=True):\n",
    "        if 'geometry' in data and 'risk_pred' in data:\n",
    "            coords = [(lat, lon) for lon, lat in data['geometry'].coords]\n",
    "            color = colormap(data['risk_pred'])\n",
    "            folium.PolyLine(\n",
    "                locations=coords,\n",
    "                color=color,\n",
    "                weight=2,\n",
    "                opacity=0.7\n",
    "            ).add_to(m)\n",
    "\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappa_rischio = visualizza_zone_di_rischio(\"../data/grafo_copy_with_geometry.pkl\")\n",
    "mappa_rischio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f45744",
   "metadata": {},
   "source": [
    "\n",
    "### Risultato-> Mappa delle zone più pericolose della città divise per colori\n",
    "\n",
    "![Mappa delle zone più pericolose della città divise per colori: ](../images/heatmap.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![ ](../images/heatmap2.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
